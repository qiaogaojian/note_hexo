---
title: Ollama + continue å®ç°æœ¬åœ° github copilot
date: 2024-08-22 20:01:04
categories: ['5.æŠ€èƒ½', 'AI', 'Agent']
tags: []
---

> åŸæ–‡åœ°å€ [zhuanlan.zhihu.com](https://zhuanlan.zhihu.com/p/686682108)

å®˜æ–¹ github copilot ä¸€å¹´ 100 ç¾å…ƒï¼Œä¹Ÿå°±æ˜¯ 700 å—ã€‚æœ¬äººæ›¾ç»è–…ä¸€ä¸ªæœˆå…è´¹çš„è¯•ç”¨è¿‡ï¼Œè‡ªåŠ¨è¡¥å…¨ä»£ç ï¼Œè¿˜èƒ½èŠå¤©è¯¢é—®çœ‹ä¸æ‡‚çš„ä»£ç å«ä¹‰ï¼Œç¡®å®å¾ˆçˆ½ï¼Œä½†æ˜¯ä»·æ ¼å®åœ¨ä¼¤ä¸èµ·ã€‚å…¶ä»–äº‘å‚å•†ä¹Ÿæä¾›äº†ç±»ä¼¼çš„å·¥å…·ï¼Œä½†æ˜¯çš†æœ‰ ä»£ç å®‰å…¨é—®é¢˜ï¼Œæ³„éœ²äº†å…¬å¸ä»£ç ï¼Œæ‰“å·¥äººä¹Ÿå¾—è·‘è·¯ã€‚

è¿™ä¹ˆå¤šå¼€æºçš„ LLM æ¨¡å‹ï¼Œèƒ½å¦ç”¨å¼€æºçš„æ¨¡å‹ï¼Œç©è‡ªå·±çš„æœ¬åœ°çš„ copilot å‘¢ï¼Ÿä¸‹é¢æˆ‘ä»¬å°±æ¥è§£é”è¿™ä¸ªæ–°å§¿åŠ¿:

<mark style="background: #fefe00A6;">ç‰¹åˆ«è¯´æ˜</mark> : **è¯¥æ–¹æ³•å¯¹äºç”µè„‘ä¸Šæ²¡æœ‰ GPU çš„ç«¥é‹ä¹Ÿé€‚ç”¨**ã€‚
  
  
### ç¬¬ä¸€æ­¥: å®‰è£… ollama

ollama åœ°å€: [Ollama](https://ollama.com/) [GitHub](https://github.com/ollama/ollama?tab=readme-ov-file#ollama) [QA](https://github.com/ollama/ollama/blob/main/docs/faq.md#where-are-models-stored)

```python
# é…ç½®ç¯å¢ƒå˜é‡: 
OLLAMA_MODELS=D:\AI\models
OLLAMA_ORIGINS=app://obsidian.md*
```
  
  
### ç¬¬äºŒæ­¥: é€šè¿‡ ollama å‘½ä»¤ä¸‹è½½æ¨¡å‹

```python
ollama run qwen2:7b           # ä¸‹è½½å¹¶è¿è¡Œ  4.4G
/set parameter num_ctx 32000  # è®¾ç½®ä¸Šä¸‹æ–‡é•¿åº¦ä¸º32000ä¸ªtoken
/save qwen2:7b                # ä¿å­˜æ¨¡å‹é…ç½®
/bye                          # é€€å‡º


# æ¨¡å‹æ¨è (ä¿å­˜ä½ç½®: D:/AI/models)  
ollama pull nomic-embed-text         # æ–‡æœ¬è½¬å‘é‡ 274M
ollama pull mxbai-embed-large        # æ–‡æœ¬è½¬å‘é‡ 669M
ollama pull starcoder2:3b            # ä»£ç è¡¥å…¨   1.7G
ollama pull deepseek-coder-v2:16b    # ä»£ç è¡¥å…¨   8.9G
ollama pull llava                    # å›¾ç‰‡è§£é‡Š   4.7G  
```
æ”¯æŒçš„æ¨¡å‹åœ°å€: [library](https://ollama.com/library)
é…ç½®æ¨¡å‹å­˜å‚¨ä½ç½®: [Ollama + Open WebUI æœ¬åœ° LLM#è‡ªå®šä¹‰æ¨¡å‹å­˜å‚¨ä½ç½®å’Œç¯å¢ƒå˜é‡ï¼ˆå¯é€‰ï¼‰](../28bae7ab0f7a286840f2bf0a5f342c3024da2942/#è‡ªå®šä¹‰æ¨¡å‹å­˜å‚¨ä½ç½®å’Œç¯å¢ƒå˜é‡ï¼ˆå¯é€‰ï¼‰) [^1]

![](https://pic1.zhimg.com/v2-3a6ed0378e74e1e8dbf4b184cceaf098_r.jpg)

**ä¸‹è½½è¿‡ç¨‹ä¸­ï¼Œå¦‚æœå‘ç°ç½‘é€Ÿå¤ªæ…¢äº†ï¼Œå¯ä»¥ ctrl +c ä¸­æ–­å‘½ä»¤ã€‚ç„¶åé‡æ–°æ‰§è¡Œ `ollama run codellama` å‘½ä»¤ï¼Œå¯ä»¥æ–­ç‚¹ç»­ä¼ ã€‚ä½†æ˜¯åƒä¸‡åˆ«å…³æœºï¼Œå¦‚æœç”µè„‘å…³æœºï¼Œå°±åªèƒ½ä»å¤´å¼€å§‹äº†ã€‚**

**ollama è¿˜æ”¯æŒå¾ˆå¤šå…¶ä»–çš„æ¨¡å‹ï¼Œå¦‚è°·æ­Œçš„ gemmaã€é˜¿é‡Œçš„ Qwenã€starcoder2 ç­‰**

![](https://pic2.zhimg.com/v2-c39389ca58346580a01be2a84e4fe3c5_r.jpg)![](https://pic1.zhimg.com/v2-42edca07188367e95305fbe94e2b4420_r.jpg)![](https://pic1.zhimg.com/v2-165dc49a99d05b31fddecb6663089068_r.jpg)
  
  
## é…ç½® Continue æ’ä»¶ (æ¨è)

å®˜ç½‘: [Continue](https://www.continue.dev/)
æºç : [GitHub - continuedev/continue](https://github.com/continuedev/continue)
æ–‡æ¡£: [Continue](https://docs.continue.dev/setup/configuration)

åŒæ—¶æœ‰åŒå­¦ç§ä¿¡ï¼Œä¸Šç¯‡æ–‡ç« ä¸­ä»‹ç»çš„ **cody ai éœ€è¦ä¸ºæ¯ä¸ªé¡¹ç›®é…ç½® `.vscode/settings.json`ï¼Œæœ‰æ²¡æœ‰ä¸€æ¬¡é…ç½®ï¼Œå…¨å±€ä½¿ç”¨çš„æ–¹æ³•ï¼Ÿä¸‹é¢ä»‹ç»çš„ continue æ’ä»¶åˆšå¥½æ»¡è¶³è¿™ä¸ªè¦æ±‚**

å®‰è£…æ’ä»¶

![](https://pic1.zhimg.com/v2-15f4ff7dd7441668a7bcf6586af45ef4_r.jpg)

é…ç½®æ’ä»¶

![](https://pic2.zhimg.com/v2-124a411cc782dfe9a84d98f6ee944185_r.jpg)

é…ç½®æ–‡ä»¶ä¿¡æ¯:

```python
{
  "models": [
    {
      "title": "ollama", # titleéšä¾¿å†™
      "model": "gemma", # modelå
      "completionOptions": {},
      "apiBase": "http://127.0.0.1:11434",
      "provider": "ollama"
    }
  ],
  ...
  "tabAutocompleteModel": {
    "title": "gemma", # titleéšä¾¿å†™
    "provider": "ollama",
    "model": "gemma", # modelå
    "apiBase": "http://127.0.0.1:11434"
  },
  ...
}
```

![](https://pic4.zhimg.com/v2-8ea93b298a341af629d00abc0cb7d063_r.jpg)

ä»£ç è¡¥å…¨æ•ˆæœ:

![](https://pic2.zhimg.com/v2-f4c086eeda80c2ef3fa98266f3edeaf1_r.jpg)

å’Œ ollama èŠå¤©:

![](https://pic2.zhimg.com/v2-44e55eca807d46b4120b5ebaf006ec29_r.jpg)

ä¸ºä»£ç æ·»åŠ æ³¨é‡Š:

![](https://pic2.zhimg.com/v2-93c210b5b25ed6f4addc020667128b3d_r.jpg)![](https://pic2.zhimg.com/v2-7abcd15b6f4558c503d04219bc7f0b5d_r.jpg)

vscode ä¸­ä½¿ç”¨ ollama å…¶å®è¿˜æœ‰å¾ˆå¤šæ’ä»¶ï¼Œå¤§å®¶å¯ä»¥è‡ªå·±å°è¯•: [https://github.com/ollama/ollama?tab=readme-ov-file#extensions--plugins](https://github.com/ollama/ollama?tab=readme-ov-file#extensions--plugins)

![](https://pic3.zhimg.com/v2-a90a6e9ee49a7345eb18dccdac48a7d6_r.jpg)
  
  
### å·¥ç¨‹çº§åˆ«ä¸Šä¸‹æ–‡

[Continue](https://docs.continue.dev/features/codebase-embeddings)

[Ollama](https://ollama.ai/)Â is the easiest way to get up and running with open-source language models. It provides an entirely local REST API for working with LLMs, including generating embeddings. We recommend using an embeddings model likeÂ `nomic-embed-text`:
```json
// ~/.continue/config.json
{
  "embeddingsProvider": {
    "provider": "ollama",
    "model": "nomic-embed-text",
    "apiBase": "http://localhost:11434" // optional, defaults to http://localhost:11434
  }
}
```
  
  
## é…ç½® Cody AI æ’ä»¶

![](https://pic1.zhimg.com/v2-ad32acc61d166426850fb1aed217b4fc_r.jpg)

**é€šè¿‡ github è´¦å·ç™»å½• cody AIï¼Œå½“ç„¶å…¶ä»– google è´¦å·ä¹Ÿåº”è¯¥æ²¡é—®é¢˜**  [å®˜ç½‘](https://sourcegraph.com/cody/manage) [æ•™ç¨‹](https://sourcegraph.com/docs/tutorials)

![](https://pic1.zhimg.com/v2-70ac2afcd4de11a4a78174f67d4d39c8_r.jpg)

**é…ç½® cody AI**

![](https://pic2.zhimg.com/v2-5f2bd1e66f2866bbac09a66a930be515_r.jpg)

**ä¿®æ”¹ cody ai çš„é…ç½®:** Cody â€º Autocomplete â€º Advanced:Provider

![](https://pic2.zhimg.com/v2-9f1a06f0d70b2020bb6070631132c3f1_r.jpg)

**ä¿®æ”¹é¡¹ç›®ç›®å½•ä¸‹çš„ `.vscode/settings.json` æ–‡ä»¶ã€‚** è¿™ä¸€æ­¥å¾ˆé‡è¦ï¼Œå¾ˆå¤šæ–‡ç« éƒ½ç¼ºå°‘äº†è¿™ä¸€æ­¥:

```python
    "cody.autocomplete.experimental.ollamaOptions": {
        "url": "http://127.0.0.1:11434",
        "model": "codellama"
    }
```

![](https://pic3.zhimg.com/v2-c651bd085255c48b3ebc712bd76586ae_r.jpg)

**æ­¤æ—¶åœ¨è¯¥ç›®å½•ä¸‹ç¼–ç ä»£ç ï¼Œå°±èƒ½è‡ªåŠ¨è¡¥å…¨äº† (å¦‚æœè¿˜ä¸èƒ½, å¯ä»¥é‡å¯ä¸‹ vscode)**:

![](https://pic2.zhimg.com/v2-54f898faa54f5aaac26636b7c549397d_r.jpg)

å’Œ cody ai èŠå¤©ï¼Œç¼–ç :

![](https://pic1.zhimg.com/v2-ff5a975ecccc4c8d247e79f4cbf03ea8_r.jpg)

  
  
## Ollama æ’ä»¶

-   [Continue](https://github.com/continuedev/continue)
-   [Obsidian Ollama plugin](https://github.com/hinterdupfinger/obsidian-ollama)
-   [Obsidian BMO Chatbot plugin](https://github.com/longy2k/obsidian-bmo-chatbot)
-   [Obsidian Local GPT plugin](https://github.com/pfrankov/obsidian-local-gpt)
-   [Page Assist](https://github.com/n4ze3m/page-assist)Â (Chrome Extension)
-   [Copilot for Obsidian plugin](https://github.com/logancyang/obsidian-copilot)
-   [Llama Coder](https://github.com/ex3ndr/llama-coder)Â (Copilot alternative using Ollama)
-   [Ollama Copilot](https://github.com/bernardo-bruning/ollama-copilot)Â (Proxy that allows you to use ollama as a copilot like Github copilot)
-   [Raycast extension](https://github.com/MassimilianoPasquini97/raycast_ollama)
-   [Discollama](https://github.com/mxyng/discollama)Â (Discord bot inside the Ollama discord channel)
-   [Logseq Ollama plugin](https://github.com/omagdy7/ollama-logseq)
-   [NotesOllama](https://github.com/andersrex/notesollama)Â (Apple Notes Ollama plugin)
-   [Dagger Chatbot](https://github.com/samalba/dagger-chatbot)
-   [Discord AI Bot](https://github.com/mekb-turtle/discord-ai-bot)
-   [Ollama Telegram Bot](https://github.com/ruecat/ollama-telegram)
-   [Hass Ollama Conversation](https://github.com/ej52/hass-ollama-conversation)
-   [Rivet plugin](https://github.com/abrenneke/rivet-plugin-ollama)
-   [Cliobot](https://github.com/herval/cliobot)Â (Telegram bot with Ollama support)
-   [Open Interpreter](https://docs.openinterpreter.com/language-model-setup/local-models/ollama)
-   [twinny](https://github.com/rjmacarthy/twinny)Â (Copilot and Copilot chat alternative using Ollama)
-   [Wingman-AI](https://github.com/RussellCanfield/wingman-ai)Â (Copilot code and chat alternative using Ollama and Hugging Face)
-   [AI Telegram Bot](https://github.com/tusharhero/aitelegrambot)Â (Telegram bot using Ollama in backend)
-   [AI ST Completion](https://github.com/yaroslavyaroslav/OpenAI-sublime-text)Â (Sublime Text 4 AI assistant plugin with Ollama support)
-   [Discord-Ollama Chat Bot](https://github.com/kevinthedang/discord-ollama)Â (Generalized TypeScript Discord Bot w/ Tuning Documentation)
-   [Discord AI chat/moderation bot](https://github.com/rapmd73/Companion)Â Chat/moderation bot written in python. Uses Ollama to create personalities.
-   [Headless Ollama](https://github.com/nischalj10/headless-ollama)Â (Scripts to automatically install ollama client & models on any OS for apps that depends on ollama server)
  
  
## å‚è€ƒ

[^1]: [Can we change where the models are stored in windows Â· Issue #2551 Â· ollama/ollama Â· GitHub](https://github.com/ollama/ollama/issues/2551)

[Local Coding Assistant. Local-Coding-Assistant | by Akshay Dongare | Medium](https://medium.com/@akshayd02/local-coding-assistant-3faa2b6719be)

{% pullquote mindmap mindmap-md %}
- ğŸ”µ
  - [Ollama + Open WebUI æœ¬åœ° LLM#è‡ªå®šä¹‰æ¨¡å‹å­˜å‚¨ä½ç½®å’Œç¯å¢ƒå˜é‡ï¼ˆå¯é€‰ï¼‰](../28bae7ab0f7a286840f2bf0a5f342c3024da2942/#è‡ªå®šä¹‰æ¨¡å‹å­˜å‚¨ä½ç½®å’Œç¯å¢ƒå˜é‡ï¼ˆå¯é€‰ï¼‰)
{% endpullquote %}